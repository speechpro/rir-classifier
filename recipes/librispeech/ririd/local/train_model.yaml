#!/bin/env inex

targ_from_chid: ???
classes_path: ???
valid_data_dir: ???
train_data_dir: ???
batch_size: ???
num_workers: ???
pin_memory: ???
model_config: ???
lr: ???
num_epochs: ???
stop_after: ???
resume_training: ???
accelerator: ???
devices: ???
num_nodes: ???
ddp_strategy: ???
val_check_interval: ???
log_aver_num: ???
train_dir: ???

__mute__: [module, execute]

plugins:
  - classes
  - valid_dataset
  - train_dataset
  - total_steps
  - model
  - parameters
  - optimizer
  - scheduler
  - criterion
  - accuracy
  - metric
  - module
  - progress
  - logger

classes:
  module: rirtk.data.classes/Classes
  exports: [num_classes]
  options:
    classes: ${classes_path}

valid_dataset:
  module: rirtk.data.dataset/BatchSet
  options:
    targ_from_chid: ${targ_from_chid}
    data_dir: ${valid_data_dir}
    batch_size: ${batch_size}

train_dataset:
  module: rirtk.data.dataset/BatchSet
  exports: [num_batches]
  options:
    targ_from_chid: ${targ_from_chid}
    data_dir: ${train_data_dir}
    batch_size: ${batch_size}

total_steps:
  module: inex.helpers/evaluate
  imports:
    num_batches: train_dataset.num_batches
  options:
    expression: 'int(1.001 * {num_batches})'

model:
  module: inex.helpers/_import_
  imports:
    output_dim: classes.num_classes
  options:
    plugin: model
    config: ${model_config}

parameters:
  module: plugins.model/parameters

optimizer:
  module: torch.optim/Adam
  imports:
    params: plugins.parameters
  options:
    lr: ${lr}

scheduler:
  module: torch.optim.lr_scheduler/OneCycleLR
  imports:
    optimizer: plugins.optimizer
    total_steps: plugins.total_steps
  options:
    max_lr: ${lr}

criterion:
  module: torch.nn/CrossEntropyLoss

accuracy:
  module: torchmetrics.classification.accuracy/Accuracy
  imports:
    num_classes: classes.num_classes
  options:
    task: multiclass

metric:
  module: rirtk.utils.metrics/MetricWrapper
  imports:
    metric: plugins.accuracy
  options:
    label: acc

module:
  module: rirtk.lightning.module/Module
  imports:
    model: plugins.model
    valid_dataset: plugins.valid_dataset
    train_dataset: plugins.train_dataset
    optimizer: plugins.optimizer
    scheduler: plugins.scheduler
    criterion: plugins.criterion
    valid_metric: plugins.metric
    train_metric: plugins.metric
  options:
    num_workers: ${num_workers}
    pin_memory: ${pin_memory}
    log_aver: ${log_aver_num}
    valid_bar_keys:
      loss: v_loss
      acc: v_acc
      err: v_err
    valid_log_keys: {}
    train_bar_keys:
      loss: t_loss
      acc: t_acc
      err: t_err
      lr: lr
    train_log_keys: {}

progress:
  module: pytorch_lightning.callbacks.progress/TQDMProgressBar
  options:
    refresh_rate: 5

logger:
  module: pytorch_lightning.loggers/CSVLogger
  options:
    save_dir: ${train_dir}

execute:
  method: rirtk.lightning.trainer/train
  imports:
    module: plugins.module
    callbacks: [plugins.progress]
    logger: plugins.logger
  options:
    num_epochs: ${num_epochs}
    stop_after: ${stop_after}
    resume_training: ${resume_training}
    accelerator: ${accelerator}
    devices: ${devices}
    num_nodes: ${num_nodes}
    val_check_interval: ${val_check_interval}
    num_sanity_val_steps: 0
    strategy: ${ddp_strategy}
    default_root_dir: ${train_dir}